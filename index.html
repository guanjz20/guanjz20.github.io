<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en">

<head>
  <meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
  <meta name="keywords" content="Jiazhi Guan; Guan Jiazhi; guanjiazhi; 官佳智">
  <meta name="description" content="Jiazhi Guan's homepage">
  <meta name="viewport" content="width=1024, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">
  <link rel="stylesheet" href="jemdoc.css" type="text/css" />
  <link rel="shortcut icon" href="myIcon.ico">
  <title>JIAZHI (JAX) GUAN</title>
  <!-- <script type="text/javascript">
    var _gaq = _gaq || [];
    _gaq.push(['_setAccount', 'UA-39824124-1']);
    _gaq.push(['_trackPageview']);
    (function () {
      var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
      ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
      var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
    })();
  </script> -->

  <style>
    body {
      width: 1024px;
      margin: 0 auto;
    }
    table {
      width: 100%;
    }
    /* img {
      max-width: 100%;
    } */
  </style>
</head>

<body>

  <div id="layout-content" style="margin-top:25px">

    <table>
      <tbody>
        <tr>
          <td width="670">
            <div id="toptitle">
              <h1>JIAZHI (JAX) GUAN <br> 官佳智<h1>
            </div>
            <h3>Ph.D.</h3>
            <p>
              Dept. of Computer Science and Technology<br>
              Tsinghua University <br>
              Beijing, China<br>
              <br>
              Email: <a href="mailto:guanjz20@mails.tsinghua.edu.cn">guanjz20 [at] mails.tsinghua.edu.cn</a>
              <br>
              <a href="https://scholar.google.com/citations?user=LocNpywAAAAJ&hl=zh-CN">[Google Scholar]</a> <a
                href="https://github.com/guanjz20">[Github]</a>
            </p>
          </td>
          <td>
            <!-- <img src="pics/me.jpg" border="0" width="200"><br> -->
            <img src="pics/me_milano.jpeg" border="0" width="350"><br>
          </td>
        <tr>
      </tbody>
    </table>

    <h2>Biography</h2>
    <p>
      Jiazhi Guan is currently a Ph.D. candidate at Dept. of Computer Science and Technology, Tsinghua University,
      supervised by Prof. Youjian Zhao. Before that, he received the Bachelor's degree at Wuhan University of Technology
      in 2020.
      His research interests include computer vision and generative modeling, specifically deepfake detection and
      digital human animation.
    </p>
    <!--
<h2>Recent Updates</h2>
<ul>
<li>
Three papers accepted by CVPR 2020.
</li>
</ul>-->

    <h2>Experiences</h2>
    <ul>

      <li>
        Visiting Student | S-Lab, Nanyang Technological University, Singapore <div style="float:right; text-align:right">Oct. 2024 – Present
        </div><br>
        Topic: Body Animation <br>
        Advisor: <a href="https://liuziwei7.github.io/">Ziwei Liu</a><br>
        </li>
  
      <li>
        Research Intern | Baidu Inc. VIS, Beijing <div style="float:right; text-align:right">Nov. 2021 – Present
        </div><br>
        Topic: Facial Animation, Body Animation<br>
        Advisor: <a href="https://hangz-nju-cuhk.github.io/">Hang Zhou</a><br>
      </li>

    </ul>



    <h2>Selected Publications </h2>
    *: equal contribution | †: Corresponding author
    <ul>

      <li>
        <b><a href="https://dl.acm.org/doi/10.1145/3680528.3687571">TALK-Act: Enhance Textural-Awareness for 2D Speaking Avatar Reenactment with Diffusion Model</b>
        <br></a>
        <b>Jiazhi Guan</b>, Quanwei Yang, Kaisiyuan Wang, Hang Zhou†, Shengyi He, Zhiliang Xu, Haocheng Feng,<br> Errui Ding, Jingdong Wang, Hongtao Xie, Youjian Zhao†, Ziwei Liu<br>
        <i>SIGGRAPH Asia Conference Proceedings (<b>SIGGRAPH Asia</b>), 2024.<br></i>
        [<a href="projects/TALK-Act">Project</a>]
        [<a href="https://arxiv.org/pdf/2410.10696">PDF</a>]
        <p style="margin-top:3px"></p>  
        </p>
      </li>


      <li>
        <b><a href="https://www.ecva.net/papers/eccv_2024/papers_ECCV/html/5783_ECCV_2024_paper.php">ReSyncer: Rewiring Style-based Generator for Unified Audio-Visually Synced Facial Performer</b>
        <br></a>
        <b>Jiazhi Guan*</b>, Zhiliang Xu*, Hang Zhou†, Kaisiyuan Wang, Shengyi He, Zhanwang Zhang, Borong Liang,<br>
        Haocheng Feng, Errui Ding, Jingtuo Liu, Jingdong Wang, Youjian Zhao†, Ziwei Liu<br>
        <i>European Conference on Computer Vision (<b>ECCV</b>, <font color='red'>Oral</font>), 2024.<br></i>
        [<a href="projects/ReSyncer">Project</a>]
        [<a href="https://arxiv.org/pdf/2408.03284">PDF</a>]
        <p style="margin-top:3px"></p>
        </p>
      </li>


      <li>
        <b><a href="https://cvpr.thecvf.com/virtual/2023/poster/22944">StyleSync: High-Fidelity Generalized and
            Personalized Lip Sync in Style-based Generator</b>
        <br></a>
        <b>Jiazhi Guan*</b>, Zhanwang Zhang*, Hang Zhou†, Tianshu Hu†, Kaisiyuan Wang, Dongliang He,<br> Haocheng Feng,
        Jingtuo Liu, Errui Ding, Ziwei Liu, Jingdong Wang<br>
        <i>IEEE Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>), 2023.<br></i>
        [<a href="projects/StyleSync">Project</a>]
        [<a href="https://arxiv.org/pdf/2305.05445">PDF</a>]
        <!-- [<a href="https://youtu.be/uuBglL2KGFc?si=vJhQkAgWRTZB_CQr">Video</a>] -->
        <!-- [<a href="https://github.com/guanjz20/StyleSync">Code</a>] -->
        <p style="margin-top:3px"></p>
        </p>
      </li>


      <li>
        <b><a href="https://ojs.aaai.org/index.php/AAAI/article/view/27762">Adversarial Robust Safeguard for Evading
            Deep Facial Manipulation</b>
        <br></a>
        <b>Jiazhi Guan</b>, Yi Zhao†, Zhuoer Xu, Changhua Meng, Ke Xu, Youjian Zhao†<br>
        <i>Association for the Advancement of Artificial Intelligence (<b>AAAI</b>), 2024<br></i>
        [<a href="https://ojs.aaai.org/index.php/AAAI/article/view/27762/27565">PDF</a>]
        [<a
          href="https://underline.io/lecture/92318-adversarial-robust-safeguard-for-evading-deep-facial-manipulation">Video</a>]
        <p style="margin-top:3px"></p>
        </p>
      </li>


      <li>
        <b><a href="https://dl.acm.org/doi/abs/10.1145/3591106.3592284">Dual-Modality Co-Learning for Unveiling Deepfake
            in Spatio-Temporal Space</b>
        <br></a>
        <b>Jiazhi Guan</b>, Hang Zhou, Zhizhi Guo, Tianshu Hu, Lirui Deng, Chengbin Quan, Meng Fang, Youjian Zhao†<br>
        <i>ACM International Conference on Multimedia Retrieval (<b>ICMR</b>, <font color='red'>Best Paper Candidate</font>), 2023<br></i>
        [<a href="https://dl.acm.org/doi/pdf/10.1145/3591106.3592284">PDF</a>]
        <p style="margin-top:3px"></p>
        </p>
      </li>

      <li>
        <b><a
            href="https://proceedings.neurips.cc/paper_files/paper/2022/hash/1d051fb631f104cb2a621451f37676b9-Abstract-Conference.html">Delving
            into Sequential Patches for Deepfake Detection</b>
        <br></a>
        <b>Jiazhi Guan</b>, Hang Zhou, Zhibin Hong, Errui Ding, Jingdong Wang, Chengbin Quan, Youjian Zhao†<br>
        <i>Conference on Neural Information Processing Systems (<b>NeurIPS</b>), 2022.<br></i>
        [<a
          href="https://proceedings.neurips.cc/paper_files/paper/2022/file/1d051fb631f104cb2a621451f37676b9-Paper-Conference.pdf">PDF</a>]
        [<a href="https://neurips.cc/virtual/2022/poster/55159">Video</a>]
        <p style="margin-top:3px"></p>
        </p>
      </li>

      <li>
        <b><a href="https://arxiv.org/abs/2207.10402">Detecting Deepfake by Creating Spatio-Temporal Regularity
            Disruption</b>
        <br></a>
        <b>Jiazhi Guan</b>, Hang Zhou, Mingming Gong, Errui Ding, Jingdong Wang, Youjian Zhao†<br>
        <i>Arxiv: 2207.10402<br></i>
        [<a href="https://arxiv.org/pdf/2207.10402">PDF</a>]
        <p style="margin-top:3px"></p>
        </p>
      </li>
    </ul>


    <h2>Honors and Awards</h2>
    <table id="Honors" border="0" width="100%">
      <tbody>
        <tr>
          <td>Outstanding Intern, Baidu VIS</td>
          <td>
            <div style="float:right; text-align:right">2024</div>
          </td>
        </tr>
        <tr>
          <td>Overall Excellence Scholarship, Tsinghua University</td>
          <td>
            <div style="float:right; text-align:right">2022,2023,2024</div>
          </td>
        </tr>
        <tr>
          <td>Third Place, DeepFake Game Competition, IJCB 2022</td>
          <td>
            <div style="float:right; text-align:right">2022</div>
          </td>
        </tr>
        <tr>
          <td>Outstanding Graduate, Hubei Provinces</td>
          <td>
            <div style="float:right; text-align:right">2020</div>
          </td>
        </tr>
        <tr>
          <td>National Scholarship, Ministry of Education, China</td>
          <td>
            <div style="float:right; text-align:right">2017,2018,2019</div>
          </td>
        </tr>
      </tbody>
    </table>


    <h2>Professional Activities</h2>
    <p>
      Conference Reviewer of: ICCV 2023, CVPR 2023, MM 2024, NeurIPS 2024 and ICLR 2024.
    </p>

    <h2>Teaching</h2>
    <table id="Teaching" border="0" width="100%">
      <tbody>
        <tr>
          <td>TA of Digital Logic Circuit, DCST, Tsinghua University</td>
          <td>Spring</td>
          <td>
            <div style="float:right; text-align:right">2021-2024</div>
          </td>
        </tr>
      </tbody>
    </table>

    <!-- <script>
      (function (i, s, o, g, r, a, m) {
        i['GoogleAnalyticsObject'] = r; i[r] = i[r] || function () {
          (i[r].q = i[r].q || []).push(arguments)
        }, i[r].l = 1 * new Date(); a = s.createElement(o),
          m = s.getElementsByTagName(o)[0]; a.async = 1; a.src = g; m.parentNode.insertBefore(a, m)
      })(window, document, 'script', 'https://www.google-analytics.com/analytics.js', 'ga');

      ga('create', 'UA-88615920-1', 'auto');
      ga('send', 'pageview');
    </script> -->
  </div>
</body>

</html>